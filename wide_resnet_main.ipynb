{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wide_resnet_main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPh9ig9Ro5bIT4ag4QYbc/Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeynep68/CIFAR100/blob/main/wide_resnet_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jNCWMcENRdM"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from wide_resnet import create_wide_resnet"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDtHhBVY4OC0"
      },
      "source": [
        "def load_data(num_classes=10):\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "  x_train = tf.cast(x_train, dtype=tf.float32)\n",
        "  x_test = tf.cast(x_test, dtype=tf.float32)\n",
        "\n",
        "  y_train = to_categorical(y_train, num_classes)\n",
        "  y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "  x_train /= 255.\n",
        "  x_test /= 255.\n",
        "\n",
        "  mean = np.mean(x_train, axis=(0,1,2))\n",
        "  std = np.std(x_train, axis=(0,1,2))\n",
        "\n",
        "  x_train = (x_train - mean) / std\n",
        "  x_test = (x_test - mean) / std\n",
        "\n",
        "  return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unN7XNkK4gXi"
      },
      "source": [
        "def lr_schedule(epoch, lr):\n",
        "  if epoch > 55:\n",
        "      lr *= 1e-2\n",
        "  elif epoch >= 40:\n",
        "      lr *= 1e-1\n",
        "\n",
        "  return lr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaojoN8B6yxs"
      },
      "source": [
        "\"\"\" Block types used in the wide resnet paper. \"\"\"\n",
        "BLOCK_TYPE = [[3,3], [3,1,3], [1,3,1], [1,3], [3,1], [3,1,1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y45I4tXU4iEl",
        "outputId": "c3ae826e-14b9-4fbe-c410-5e874261a018"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  (x_train, y_train), (x_test, y_test) = load_data()\n",
        "\n",
        "  lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "  model = create_wide_resnet(x_train, avg_pool=8, k=4, n=[2,2,2], kernels=BLOCK_TYPE[6], learning_rate=1e-3)\n",
        "\n",
        "  EPOCHS = 70\n",
        "  BATCH_SIZE = 128\n",
        "\n",
        "  training = model.fit(x_train,\n",
        "                      y_train,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      epochs=EPOCHS,\n",
        "                      validation_data=(x_test, y_test),\n",
        "                      callbacks=[lr_scheduler])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "391/391 [==============================] - 45s 109ms/step - loss: 1.9023 - accuracy: 0.4118 - val_loss: 2.5389 - val_accuracy: 0.2742\n",
            "Epoch 2/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 1.3996 - accuracy: 0.5763 - val_loss: 1.6273 - val_accuracy: 0.5220\n",
            "Epoch 3/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 1.1634 - accuracy: 0.6555 - val_loss: 1.3247 - val_accuracy: 0.6284\n",
            "Epoch 4/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 1.0283 - accuracy: 0.7010 - val_loss: 1.4571 - val_accuracy: 0.6211\n",
            "Epoch 5/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.9455 - accuracy: 0.7322 - val_loss: 1.3985 - val_accuracy: 0.6036\n",
            "Epoch 6/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.8750 - accuracy: 0.7588 - val_loss: 1.5094 - val_accuracy: 0.6261\n",
            "Epoch 7/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.8185 - accuracy: 0.7851 - val_loss: 1.2037 - val_accuracy: 0.6651\n",
            "Epoch 8/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.7731 - accuracy: 0.8020 - val_loss: 1.0808 - val_accuracy: 0.7273\n",
            "Epoch 9/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.7373 - accuracy: 0.8174 - val_loss: 1.2522 - val_accuracy: 0.6903\n",
            "Epoch 10/120\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.7103 - accuracy: 0.8267 - val_loss: 1.1024 - val_accuracy: 0.7339\n",
            "Epoch 11/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.6892 - accuracy: 0.8373 - val_loss: 1.3203 - val_accuracy: 0.6966\n",
            "Epoch 12/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.6694 - accuracy: 0.8447 - val_loss: 1.2292 - val_accuracy: 0.7364\n",
            "Epoch 13/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.6529 - accuracy: 0.8545 - val_loss: 1.2923 - val_accuracy: 0.7223\n",
            "Epoch 14/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.6319 - accuracy: 0.8622 - val_loss: 1.0239 - val_accuracy: 0.7737\n",
            "Epoch 15/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.6176 - accuracy: 0.8686 - val_loss: 1.0729 - val_accuracy: 0.7647\n",
            "Epoch 16/120\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 0.6080 - accuracy: 0.8742 - val_loss: 1.0604 - val_accuracy: 0.7672\n",
            "Epoch 17/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.6023 - accuracy: 0.8762 - val_loss: 0.8575 - val_accuracy: 0.8081\n",
            "Epoch 18/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5842 - accuracy: 0.8856 - val_loss: 1.2155 - val_accuracy: 0.7401\n",
            "Epoch 19/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5773 - accuracy: 0.8877 - val_loss: 1.0207 - val_accuracy: 0.7897\n",
            "Epoch 20/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5713 - accuracy: 0.8927 - val_loss: 1.1062 - val_accuracy: 0.7639\n",
            "Epoch 21/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5663 - accuracy: 0.8930 - val_loss: 1.2773 - val_accuracy: 0.7251\n",
            "Epoch 22/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5608 - accuracy: 0.8992 - val_loss: 0.8814 - val_accuracy: 0.8197\n",
            "Epoch 23/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5480 - accuracy: 0.9039 - val_loss: 0.8495 - val_accuracy: 0.8240\n",
            "Epoch 24/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5522 - accuracy: 0.9040 - val_loss: 1.1225 - val_accuracy: 0.7855\n",
            "Epoch 25/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5459 - accuracy: 0.9077 - val_loss: 0.9728 - val_accuracy: 0.7949\n",
            "Epoch 26/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5360 - accuracy: 0.9110 - val_loss: 0.8794 - val_accuracy: 0.8287\n",
            "Epoch 27/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5360 - accuracy: 0.9137 - val_loss: 0.9223 - val_accuracy: 0.8183\n",
            "Epoch 28/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5345 - accuracy: 0.9149 - val_loss: 1.2879 - val_accuracy: 0.7443\n",
            "Epoch 29/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5282 - accuracy: 0.9177 - val_loss: 0.8934 - val_accuracy: 0.8210\n",
            "Epoch 30/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5185 - accuracy: 0.9208 - val_loss: 1.4624 - val_accuracy: 0.7275\n",
            "Epoch 31/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5247 - accuracy: 0.9217 - val_loss: 0.9429 - val_accuracy: 0.8124\n",
            "Epoch 32/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5117 - accuracy: 0.9258 - val_loss: 1.1679 - val_accuracy: 0.7764\n",
            "Epoch 33/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5178 - accuracy: 0.9235 - val_loss: 0.9865 - val_accuracy: 0.8228\n",
            "Epoch 34/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5116 - accuracy: 0.9268 - val_loss: 1.0033 - val_accuracy: 0.8170\n",
            "Epoch 35/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5156 - accuracy: 0.9257 - val_loss: 1.0593 - val_accuracy: 0.8167\n",
            "Epoch 36/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5076 - accuracy: 0.9287 - val_loss: 1.1513 - val_accuracy: 0.7863\n",
            "Epoch 37/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5069 - accuracy: 0.9316 - val_loss: 1.0943 - val_accuracy: 0.8043\n",
            "Epoch 38/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.5034 - accuracy: 0.9322 - val_loss: 1.0751 - val_accuracy: 0.7972\n",
            "Epoch 39/120\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 0.5008 - accuracy: 0.9328 - val_loss: 1.0990 - val_accuracy: 0.8123\n",
            "Epoch 40/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.4967 - accuracy: 0.9354 - val_loss: 1.0422 - val_accuracy: 0.8066\n",
            "Epoch 41/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.4118 - accuracy: 0.9665 - val_loss: 0.7434 - val_accuracy: 0.8784\n",
            "Epoch 42/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3805 - accuracy: 0.9774 - val_loss: 0.7444 - val_accuracy: 0.8810\n",
            "Epoch 43/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3765 - accuracy: 0.9789 - val_loss: 0.7448 - val_accuracy: 0.8811\n",
            "Epoch 44/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3768 - accuracy: 0.9788 - val_loss: 0.7441 - val_accuracy: 0.8804\n",
            "Epoch 45/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3764 - accuracy: 0.9795 - val_loss: 0.7459 - val_accuracy: 0.8809\n",
            "Epoch 46/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3761 - accuracy: 0.9793 - val_loss: 0.7456 - val_accuracy: 0.8807\n",
            "Epoch 47/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3759 - accuracy: 0.9792 - val_loss: 0.7446 - val_accuracy: 0.8804\n",
            "Epoch 48/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3764 - accuracy: 0.9790 - val_loss: 0.7463 - val_accuracy: 0.8803\n",
            "Epoch 49/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3772 - accuracy: 0.9784 - val_loss: 0.7448 - val_accuracy: 0.8804\n",
            "Epoch 50/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3768 - accuracy: 0.9784 - val_loss: 0.7450 - val_accuracy: 0.8802\n",
            "Epoch 51/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3760 - accuracy: 0.9796 - val_loss: 0.7462 - val_accuracy: 0.8804\n",
            "Epoch 52/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3766 - accuracy: 0.9785 - val_loss: 0.7463 - val_accuracy: 0.8807\n",
            "Epoch 53/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3769 - accuracy: 0.9789 - val_loss: 0.7461 - val_accuracy: 0.8802\n",
            "Epoch 54/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3778 - accuracy: 0.9790 - val_loss: 0.7461 - val_accuracy: 0.8806\n",
            "Epoch 55/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3765 - accuracy: 0.9792 - val_loss: 0.7454 - val_accuracy: 0.8802\n",
            "Epoch 56/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3760 - accuracy: 0.9788 - val_loss: 0.7463 - val_accuracy: 0.8800\n",
            "Epoch 57/120\n",
            "391/391 [==============================] - 42s 107ms/step - loss: 0.3749 - accuracy: 0.9794 - val_loss: 0.7467 - val_accuracy: 0.8801\n",
            "Epoch 58/120\n",
            "312/391 [======================>.......] - ETA: 8s - loss: 0.3773 - accuracy: 0.9789"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-234b4ac040db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                       callbacks=[lr_scheduler])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH7gIFPL4x_y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}